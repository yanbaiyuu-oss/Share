import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
from typing import Callable, Dict, Any, List
import pandas_ta as ta
import numpy as np
import xlsxwriter

# 忽略 pandas 的 SettingWithCopyWarning
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)


# ==============================================================================
# 核心工具函数和配置
# ==============================================================================
class Config:
    """程序配置类"""

    def __init__(self):
        self.HOME_DIRECTORY = os.path.expanduser('~')
        self.SAVE_DIRECTORY = os.path.join(self.HOME_DIRECTORY, 'Downloads', 'CoreNews_Reports')
        self.TEMP_DATA_DIRECTORY = os.path.join(self.SAVE_DIRECTORY, 'ShareData')
        self.DATA_FETCH_RETRIES = 3
        self.DATA_FETCH_DELAY = 5
        self.MAX_WORKERS = 15
        self.CODE_ALIASES = {'代码': '股票代码', '证券代码': '股票代码', '股票代码': '股票代码'}
        # 别名已包含所有常见名称
        self.NAME_ALIASES = {'名称': '股票简称', '股票名称': '股票简称', '股票简称': '股票简称', '简称': '股票简称',
                             '简': '股票简称', '证券名称': '股票简称'}
        # === 价格别名修复 v5：涵盖更多实时行情价格字段 ===
        self.PRICE_ALIASES = {'最新价': '最新价', '现价': '最新价', '当前价格': '最新价', '今收盘': '最新价',
                              '收盘': '最新价', '收盘价': '最新价'}


def format_stock_code(code: str) -> str:
    """根据股票代码的开头数字，添加市场前缀。"""
    code_str = str(code).zfill(6)
    if code_str.startswith('6'):
        return 'sh' + code_str
    elif code_str.startswith(('0', '3')):
        return 'sz' + code_str
    elif code_str.startswith(('4', '8')):
        return 'bj' + code_str
    return code_str


# ==============================================================================
# 核心分析类 (集成 Fetching, Processing, Reporting)
# ==============================================================================
class StockAnalyzer:
    """
    股票数据获取、处理、分析和报告生成的核心类。
    """

    def __init__(self):
        self.config = Config()
        self.today_str = datetime.now().strftime("%Y%m%d")
        self.temp_dir = self.config.TEMP_DATA_DIRECTORY
        os.makedirs(self.temp_dir, exist_ok=True)
        self.executor = ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS)
        self.start_time = time.time()

    def _get_file_path(self, base_name: str, cleaned: bool = False) -> str:
        """
        生成临时数据文件的完整路径。
        如果 cleaned=True, 则添加 "_经清洗" 后缀。
        """
        suffix = "_经清洗" if cleaned else ""
        file_name = f"{base_name}{suffix}_{self.today_str}.txt"
        return os.path.join(self.temp_dir, file_name)

    def _load_data_from_cache(self, file_path: str) -> pd.DataFrame:
        """从缓存加载数据。"""
        if os.path.exists(file_path):
            try:
                # 使用 '|' 分隔符，并确保股票代码是字符串格式
                df = pd.read_csv(file_path, sep='|', encoding='utf-8', dtype={'股票代码': str})
                print(f"  - 发现缓存，加载: {os.path.basename(file_path)}")
                return df
            except Exception as e:
                print(f"[WARN] 加载缓存 {os.path.basename(file_path)} 失败: {e}，将重新获取。")
        return pd.DataFrame()

    def _save_data_to_cache(self, df: pd.DataFrame, file_path: str):
        """保存数据到缓存。"""
        try:
            df.to_csv(file_path, sep='|', index=False, encoding='utf-8')
        except Exception as e:
            print(f"[ERROR] 保存数据到缓存 {os.path.basename(file_path)} 失败: {e}")

    def _safe_ak_fetch(self, fetch_func: Callable, file_base_name: str, **kwargs: Any) -> pd.DataFrame:
        """带缓存和重试的 AKShare 数据获取封装，并保存清洗后的数据。"""

        # 1. 尝试从【清洗后的缓存】加载数据
        cleaned_file_path = self._get_file_path(file_base_name, cleaned=True)
        cached_df = self._load_data_from_cache(cleaned_file_path)
        if not cached_df.empty:
            return cached_df

        # 2. 如果清洗后的缓存不存在，则尝试从原始获取
        df = pd.DataFrame()
        for i in range(self.config.DATA_FETCH_RETRIES):
            try:
                print(f"  - 正在尝试第 {i + 1}/{self.config.DATA_FETCH_RETRIES} 次获取数据: {file_base_name}...")
                df = fetch_func(**kwargs)
                if df is not None and not df.empty:
                    break  # 成功获取数据，跳出重试循环
                else:
                    print(f"[WARN] 数据返回为空或无效: {file_base_name}，重试中。")
                    time.sleep(self.config.DATA_FETCH_DELAY)
            except Exception as e:
                print(f"[ERROR] 获取 {file_base_name} 时出错: {e}，将在 {self.config.DATA_FETCH_DELAY} 秒后重试。")
                time.sleep(self.config.DATA_FETCH_DELAY)

        if df.empty:
            print(f"[FATAL] 所有重试均失败，返回空 DataFrame: {file_base_name}")
            return pd.DataFrame()

        # 3. 清洗数据并保存到带有 "_经清洗" 后缀的缓存文件
        cleaned_df = self._clean_and_standardize(df, file_base_name)
        if not cleaned_df.empty:
            self._save_data_to_cache(cleaned_df, cleaned_file_path)

        return cleaned_df

    def _clean_and_standardize(self, df: pd.DataFrame, df_name: str) -> pd.DataFrame:
        """通用数据清洗和列名标准化。"""
        if df.empty: return df

        # 1. 标准化列名：使用 Config 中的别名映射
        for old, new in self.config.CODE_ALIASES.items():
            if old in df.columns: df.rename(columns={old: new}, inplace=True)
        for old, new in self.config.NAME_ALIASES.items():
            if old in df.columns: df.rename(columns={old: new}, inplace=True)
        for old, new in self.config.PRICE_ALIASES.items():
            if old in df.columns: df.rename(columns={old: new}, inplace=True)

        if '股票代码' not in df.columns:
            # print(f"[WARN] {df_name} 数据中未找到 '股票代码' 列，跳过清洗。")
            return pd.DataFrame()

        # 2. 清洗数据
        df.dropna(subset=['股票代码'], inplace=True)
        df.drop_duplicates(subset=['股票代码'], inplace=True)
        df['股票代码'] = df['股票代码'].astype(str).str.zfill(6)

        # === 核心修复点：强制对 '最新价' 字段进行数值转换 (确保是数字类型，无效值转为 NaN) ===
        if '最新价' in df.columns:
            # 使用 errors='coerce' 将任何非数字值强制转换为 NaN，确保列类型为 float
            df['最新价'] = pd.to_numeric(df['最新价'], errors='coerce')
        # ========================================================

        # 3. 过滤ST股 (依赖 '股票简称' 列)
        if '股票简称' not in df.columns:
            # 如果没有简称，就无法过滤 ST 股，但仍返回清洗过代码格式的 DF
            cleaned_df = df.copy()
        else:
            cleaned_df = df[~df['股票简称'].str.contains('ST|st|退市|bj|BJ', case=False, na=False)].copy()

        if len(cleaned_df) == 0:
            print(f"[WARN] {df_name} 数据清洗后为空。")
            return pd.DataFrame()

        return cleaned_df

    def _get_all_raw_data(self) -> Dict[str, pd.DataFrame]:
        """集中获取所有数据源。"""
        print("\n>>> 正在初始化数据获取和缓存检查...")

        # 1. 基础行情和研报数据
        data = {
            'spot_data_all': self._safe_ak_fetch(ak.stock_zh_a_spot, "A股实时行情"),
            'main_report_raw': self._safe_ak_fetch(ak.stock_profit_forecast_em, "主力研报盈利预测"),
            'financial_abstract_raw': self._safe_ak_fetch(ak.stock_financial_abstract, "财务摘要数据"),
            'market_fund_flow_raw': self._safe_ak_fetch(ak.stock_fund_flow_individual, "市场资金流向",
                                                        symbol="5日排行"),
            'strong_stocks_raw': self._safe_ak_fetch(ak.stock_zt_pool_strong_em, "强势股池",
                                                     date=datetime.now().strftime('%Y%m%d')),
            'consecutive_rise_raw': self._safe_ak_fetch(ak.stock_rank_lxsz_ths, "连续上涨"),
            'ljqs_raw': self._safe_ak_fetch(ak.stock_rank_ljqs_ths, "量价齐升"),
            'cxfl_raw': self._safe_ak_fetch(ak.stock_rank_cxfl_ths, "持续放量"),
        }

        # 2. 均线突破数据 (Akshare接口参数不同，需分开获取)
        data['xstp_10_raw'] = self._safe_ak_fetch(ak.stock_rank_xstp_ths, "向上突破10日均线", symbol="10日均线")
        data['xstp_30_raw'] = self._safe_ak_fetch(ak.stock_rank_xstp_ths, "向上突破30日均线", symbol="30日均线")
        data['xstp_60_raw'] = self._safe_ak_fetch(ak.stock_rank_xstp_ths, "向上突破60日均线", symbol="30日均线")

        # 3. 行业板块数据 (成分股需要实时获取，不适合缓存)
        print("\n>>> 正在获取行业板块成分股...")
        industry_board_df = self._safe_ak_fetch(ak.stock_board_industry_name_em, '行业板块名称')
        # 注意：这里 Top Industry Constituent 的缓存名需要独立，以避免与 _safe_ak_fetch 冲突
        data['top_industry_cons_df'] = self._get_top_industry_constituents(industry_board_df)
        data['industry_board_df'] = industry_board_df  # 原始板块名称用于报告

        return data

    def _get_top_industry_constituents(self, industry_board_df: pd.DataFrame) -> pd.DataFrame:
        """获取涨幅前10板块的成分股。"""
        if industry_board_df.empty or '板块名称' not in industry_board_df.columns:
            return pd.DataFrame()

        # 使用一个独立的缓存文件来存储合并后的成分股数据
        cache_name = "TopIndustryConstituents_经清洗"
        cleaned_file_path = self._get_file_path(cache_name, cleaned=True)
        cached_df = self._load_data_from_cache(cleaned_file_path)
        if not cached_df.empty:
            return cached_df

        top_industries = industry_board_df.sort_values(by='涨跌幅', ascending=False).head(10)
        all_constituents = []

        # 使用 ThreadPoolExecutor 并行获取成分股
        future_to_industry = {
            self.executor.submit(
                # 由于这是短时获取且清洗逻辑简单，这里直接使用 ak.stock_board_industry_cons_em
                ak.stock_board_industry_cons_em,
                symbol=row['板块名称']
            ): row['板块名称']
            for _, row in top_industries.iterrows()
        }

        for future in as_completed(future_to_industry):
            industry_name = future_to_industry[future]
            try:
                constituents_df = future.result()
                if constituents_df is not None and not constituents_df.empty:
                    if '代码' in constituents_df.columns:
                        constituents_df.rename(columns={'代码': '股票代码'}, inplace=True)

                    # 基础清洗和标准化：代码格式化
                    if '股票代码' in constituents_df.columns:
                        constituents_df['股票代码'] = constituents_df['股票代码'].astype(str).zfill(6)
                        constituents_df['所属板块'] = industry_name

                        # 仅保留代码和板块信息，并去重
                        cleaned_constituents = constituents_df[['股票代码', '所属板块']].drop_duplicates()
                    all_constituents.append(cleaned_constituents)

            except Exception as e:
                print(f"[ERROR] 错误：获取 {industry_name} 的成分股时出错: {e}")

        if all_constituents:
            final_df = pd.concat(all_constituents, ignore_index=True).drop_duplicates(subset=['股票代码'])
            # 保存到缓存
            self._save_data_to_cache(final_df, cleaned_file_path)
            return final_df
        return pd.DataFrame()

    def _fetch_hist_data_parallel(self, codes: List[str], days: int) -> pd.DataFrame:
        """
        并行获取指定股票的历史数据，并强制将 OHLCV 列名统一为英文小写。
        """
        print(f"\n正在为 {len(codes)} 只股票下载 {days} 天的历史数据...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        start_date_str = start_date.strftime("%Y%m%d")
        end_date_str = end_date.strftime("%Y%m%d")

        # 缓存文件名增加代码数量和 "_经清洗" 后缀
        cache_name = f"MACD_hist_data_cache_{len(codes)}"
        file_path = self._get_file_path(cache_name, cleaned=True)
        cached_df = self._load_data_from_cache(file_path)

        if not cached_df.empty:
            # FIX: 历史数据无论来自哪里，都使用标准英文列名
            # 确保 'date' 字段存在且格式正确
            if 'date' in cached_df.columns:
                cached_df['date'] = pd.to_datetime(cached_df['date']).dt.strftime('%Y-%m-%d')

            # 确保关键英文列存在
            if 'close' in cached_df.columns and 'open' in cached_df.columns:
                return cached_df
            else:
                print("[WARN] 历史数据缓存文件缺少关键英文列，将重新获取。")

        all_data = []
        future_to_code = {}
        with ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) as executor:
            for code in codes:
                future = executor.submit(
                    ak.stock_zh_a_hist_tx,
                    symbol=format_stock_code(code),
                    start_date=start_date_str,
                    end_date=end_date_str,
                    adjust="hfq"  # 前复权
                )
                future_to_code[future] = code

        for future in as_completed(future_to_code):
            code = future_to_code[future]
            try:
                hist_df = future.result()
                if hist_df is not None and not hist_df.empty:

                    # **核心修复点：强制统一列名为英文小写**
                    hist_df.rename(columns={
                        'date': 'date', '日期': 'date',
                        'open': 'open', '开盘': 'open',
                        'close': 'close', '收盘': 'close',
                        'high': 'high', '最高': 'high',
                        'low': 'low', '最低': 'low',
                        'volume': 'volume', '成交量': 'volume', 'amount': 'volume',  # 假设 amount 是成交量
                    }, inplace=True, errors='ignore')

                    hist_df['股票代码'] = code

                    # 确保日期是字符串格式
                    if 'date' in hist_df.columns:
                        hist_df['date'] = pd.to_datetime(hist_df['date']).dt.strftime('%Y-%m-%d')

                    # 只保留需要的列
                    cols_to_keep = ['date', 'open', 'close', 'high', 'low', 'volume', '股票代码']
                    hist_df = hist_df[[col for col in cols_to_keep if col in hist_df.columns]]

                    all_data.append(hist_df)

            except Exception as e:
                # print(f"[ERROR] 错误：获取 {code} 的历史数据时出错: {e}")
                pass

        if all_data:
            merged_df = pd.concat(all_data, ignore_index=True)
            # 保存到缓存
            self._save_data_to_cache(merged_df, file_path)
            return merged_df
        return pd.DataFrame()

    def _process_ta_signals(self, all_codes: List[str], hist_df_all: pd.DataFrame, spot_df: pd.DataFrame) -> Dict[
        str, pd.DataFrame]:
        """计算并提取所有技术指标信号。"""
        print(f"\n正在对 {len(all_codes)} 只股票进行技术分析...")

        ta_signals = {'MACD': [], 'KDJ': [], 'CCI': [], 'RSI': [], 'BOLL': []}

        if hist_df_all.empty:
            print("[WARN] 历史数据为空，跳过技术分析。")
            return {key: pd.DataFrame() for key in ta_signals.keys()}

        # 确保数据是连续的且已排序 (使用标准化的 'date' 列)
        hist_df_all.sort_values(['股票代码', 'date'], inplace=True)

        for code in all_codes:
            # df 现在应该已经包含了 'open', 'close', 'high', 'low' 等标准列名
            df = hist_df_all[hist_df_all['股票代码'] == code].copy()

            if df.empty or len(df) < 30:  # 至少需要30条数据用于BOLL和KDJ
                continue

            # 确保所需列是数字类型 (使用英文列名)
            for col in ['close', 'open', 'high', 'low']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            df.dropna(subset=['close'], inplace=True)
            if df.empty: continue

            # 确保关键列存在 (现在只检查英文小写)
            if 'close' not in df.columns or 'open' not in df.columns or 'high' not in df.columns or 'low' not in df.columns:
                print(f"[ERROR] 股票 {code}: 历史数据中缺少必要的 OHLC 列，跳过 TA 计算。")
                continue

            try:
                # 1. MACD (金叉)
                # 由于列名已标准化，MACD可以直接计算
                df.ta.macd(append=True, fast=12, slow=26, signal=9, close='close')
                macd_cols = [col for col in df.columns if
                             col.startswith('MACD_') or col.startswith('MACDH_') or col.startswith('MACDS_')]
                if len(macd_cols) >= 3:
                    # 获取 MACDH (柱状线) 的列名，确保它是存在的
                    macd_h_col = [col for col in macd_cols if col.startswith('MACDH_')][0]
                    # 找到最近的金叉信号: DIF 穿过 DEA，或 MACDH 由负转正
                    # 这里使用 MACDH 由负转正 (MACDH > 0 and MACDH.shift(1) <= 0)
                    df['MACD_CROSS'] = np.where(
                        (df[macd_h_col] > 0) & (df[macd_h_col].shift(1) <= 0), 1, 0)
                    if df['MACD_CROSS'].iloc[-1] == 1:
                        # 仅记录信号，不包含评分
                        ta_signals['MACD'].append({'股票代码': code, 'MACD_Signal': '金叉'})

                # 2. KDJ (超卖区金叉)
                df.ta.stoch(append=True, close='close', high='high', low='low')
                kdj_cols = [col for col in df.columns if col.startswith('STOCHk_') or col.startswith('STOCHd_')]
                if len(kdj_cols) >= 2:
                    k_col = kdj_cols[0]
                    d_col = kdj_cols[1]
                    # K<20 区域
                    df['KDJ_OVS'] = np.where((df[k_col] < 20) & (df[d_col] < 20), 1, 0)
                    # 金叉
                    df['KDJ_CROSS'] = np.where(
                        (df[k_col] > df[d_col]) & (df[k_col].shift(1) <= df[d_col].shift(1)), 1, 0)

                    # 超卖区金叉
                    if df['KDJ_OVS'].iloc[-5:-1].sum() > 0 and df['KDJ_CROSS'].iloc[-1] == 1:
                        # 仅记录信号，不包含评分
                        ta_signals['KDJ'].append({'股票代码': code, 'KDJ_Signal': '超卖区金叉'})

                # 3. CCI (超卖)
                df.ta.cci(append=True, close='close', high='high', low='low')
                cci_cols = [col for col in df.columns if col.startswith('CCI_')]
                if cci_cols:
                    cci_col = cci_cols[0]
                    if df[cci_col].iloc[-1] < -100:
                        # 仅记录信号，不包含评分
                        ta_signals['CCI'].append(
                            {'股票代码': code, 'CCI_Signal': f"超卖 ({df[cci_col].iloc[-1]:.2f})"})

                # 4. RSI (超卖低位)
                df.ta.rsi(append=True, close='close')
                rsi_cols = [col for col in df.columns if col.startswith('RSI_')]
                if rsi_cols:
                    rsi_col = rsi_cols[0]
                    if df[rsi_col].iloc[-1] < 30:
                        # 仅记录信号，不包含评分
                        ta_signals['RSI'].append(
                            {'股票代码': code, 'RSI_Signal': f"超卖低位 ({df[rsi_col].iloc[-1]:.2f})"})

                # 5. BOLL (低波/缩口)
                df.ta.bbands(append=True, length=20, std=2, close='close')
                boll_cols = [col for col in df.columns if col.startswith('BBL_')]
                if boll_cols:
                    lower_band = boll_cols[0]
                    upper_band = [col for col in df.columns if col.startswith('BBU_')][0]
                    # 计算带宽
                    df['BOLL_BANDWIDTH'] = (df[upper_band] - df[lower_band]) / df['close']
                    # 最近 N 天的平均带宽低于历史平均带宽（表示缩口）
                    if df['BOLL_BANDWIDTH'].iloc[-5:].mean() < df['BOLL_BANDWIDTH'].mean():
                        # 仅记录信号，不包含评分
                        ta_signals['BOLL'].append({'股票代码': code, 'BOLL_Signal': '低波/缩口'})

            except KeyError as ke:
                # 捕获 MACDH_12_26_9 或其他指标列名找不到的错误
                print(f"[ERROR] 计算 {code} 的 TA 指标时出错: 关键指标列名丢失 ({ke})")
            except Exception as e:
                print(f"[ERROR] 计算 {code} 的 TA 指标时出错: {e}")
                continue

        # 将结果列表转换为 DataFrame
        final_ta_dfs = {}
        for key, value in ta_signals.items():
            final_ta_dfs[key] = pd.DataFrame(value)

        return final_ta_dfs

    def _process_xstp_and_filter(self, raw_data: Dict[str, pd.DataFrame], spot_df: pd.DataFrame) -> pd.DataFrame:
        """处理并合并均线突破数据，并进行多头排列筛选。"""
        print("正在处理并合并均线突破数据...")

        # 1. 清洗均线数据
        processed_df10 = raw_data['xstp_10_raw'].rename(columns={'最新价': '10日均线最新价'})
        processed_df30 = raw_data['xstp_30_raw'].rename(columns={'最新价': '30日均线最新价'})
        processed_df60 = raw_data['xstp_60_raw'].rename(columns={'最新价': '60日均线最新价'})

        # 2. 合并
        # 使用concat时只保留代码和简称，避免价格列冲突
        merged_df = pd.concat([
            processed_df10[['股票代码', '股票简称']].dropna(subset=['股票代码']),
            processed_df30[['股票代码', '股票简称']].dropna(subset=['股票代码']),
            processed_df60[['股票代码', '股票简称']].dropna(subset=['股票代码'])
        ]).drop_duplicates(subset=['股票代码'])

        # 3. 重新合并均线价格，确保同一行有所有数据
        xstp_base = merged_df[['股票代码', '股票简称']].drop_duplicates()
        xstp_base = pd.merge(xstp_base, processed_df10[['股票代码', '10日均线最新价']], on='股票代码', how='left')
        xstp_base = pd.merge(xstp_base, processed_df30[['股票代码', '30日均线最新价']], on='股票代码', how='left')
        xstp_base = pd.merge(xstp_base, processed_df60[['股票代码', '60日均线最新价']], on='股票代码', how='left')

        # 4. 合并实时价格 (此处仍然按代码合并，以便于均线计算的准确性)
        xstp_base = pd.merge(xstp_base, spot_df[['股票代码', '最新价']], on='股票代码', how='left')

        # 5. 类型转换和过滤
        cols_to_convert = [col for col in xstp_base.columns if '最新价' in col or col == '最新价']
        for col in cols_to_convert:
            # 导入 numpy 是为了使用 np.inf，所以在这里重新导入或使用 float('-inf')
            xstp_base[col] = pd.to_numeric(xstp_base[col], errors='coerce')

        # 过滤条件: 1. 最新价>10日均线 2. 多头排列 (10>30 或 30>60)
        filtered_df = xstp_base[
            (xstp_base['最新价'] > xstp_base['10日均线最新价']) &
            (
                    (xstp_base['10日均线最新价'] > xstp_base['30日均线最新价'].fillna(float('-inf'))) |
                    (xstp_base['30日均线最新价'] > xstp_base['60日均线最新价'].fillna(float('-inf')))
            )
            ].copy()

        # 添加完全多头排列标记
        filtered_df['完全多头排列'] = filtered_df.apply(
            # 需要确保在计算前处理 NaN 值，这里使用一个较大的负数代替 NaN
            lambda row: '是' if row['10日均线最新价'] > row['30日均线最新价'] and row['30日均线最新价'] > row[
                '60日均线最新价'] else '否',
            axis=1
        )

        # 重新命名 '最新价' 为 '当前价格' 以避免与均线价混淆
        filtered_df.rename(columns={'最新价': '当前价格'}, inplace=True)
        return filtered_df.fillna('N/A')

    def _consolidate_data(self, processed_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """【已按用户要求使用股票简称进行价格关联】合并所有数据源和信号，生成最终汇总报告。"""
        print("\n>>> 正在汇总所有数据和信号 (技术指标作为独立列)...")

        # 1. 提取所有有信号的股票代码作为基础 (V6: 由于输入数据源已经被 run() 严格过滤，这里收集的 codes 就是最终 Universe)
        all_codes = set()
        data_sources = [
            processed_data.get('processed_main_report'),
            processed_data.get('processed_xstp_df'),
            processed_data.get('market_fund_flow_raw'),
            processed_data.get('strong_stocks_raw'),
            processed_data.get('consecutive_rise_raw'),
            processed_data.get('ljqs_raw'),
            processed_data.get('cxfl_raw'),
            processed_data.get('MACD', pd.DataFrame()),
            processed_data.get('KDJ', pd.DataFrame()),
            processed_data.get('CCI', pd.DataFrame()),
            processed_data.get('RSI', pd.DataFrame()),
            processed_data.get('BOLL', pd.DataFrame()),
        ]

        for df in data_sources:
            if df is not None and not df.empty and '股票代码' in df.columns:
                all_codes.update(df['股票代码'].unique())

        if not all_codes: return pd.DataFrame()
        final_df = pd.DataFrame(list(all_codes), columns=['股票代码'])

        # 强制代码列表为字符串类型
        final_df['股票代码'] = final_df['股票代码'].astype(str)

        # 2. 鲁棒地合并基础信息 (简称, 价格)
        spot_df = processed_data.get('spot_data_all', pd.DataFrame())
        report_df_base = processed_data.get('processed_main_report', pd.DataFrame())

        # 确保实时行情代码列表是字符串类型
        if '股票代码' in spot_df.columns:
            spot_df['股票代码'] = spot_df['股票代码'].astype(str)

        # 2a. 构建名称源：从实时行情和研报数据中收集名称 (仍以代码为基础确保唯一性)
        name_source_spot = spot_df[['股票代码', '股票简称']].drop_duplicates(
            subset=['股票代码']) if '股票简称' in spot_df.columns else pd.DataFrame()
        name_source_report = report_df_base[['股票代码', '股票简称']].drop_duplicates(
            subset=['股票代码']) if '股票简称' in report_df_base.columns else pd.DataFrame()

        # 2b. 合并所有名称源：优先使用实时行情 (spot_df) 的名称
        all_names = pd.concat([name_source_spot, name_source_report]).drop_duplicates(subset=['股票代码'], keep='first')

        # 2c. 合并名称到最终报告 (按代码合并，保证基础表的简称是正确的)
        final_df = pd.merge(final_df, all_names, on='股票代码', how='left')

        # --- V5 价格获取和清洗增强：按用户要求使用 '股票简称' 进行关联 ---

        # 1. 从实时行情数据中提取用于价格合并的列 (简称和最新价)
        if '股票简称' not in spot_df.columns:
            # 严重警告：如果实时行情数据中没有股票简称，则回退到使用股票代码。
            print("[FATAL] 实时行情数据中缺少 '股票简称' 列，无法按要求按简称关联。回退到按代码关联。")
            price_source_key = '股票代码'
            price_source = spot_df[['股票代码', '最新价']].copy()
        else:
            price_source_key = '股票简称'
            price_source = spot_df[['股票简称', '最新价']].copy()

            # 2. 严格筛选：对价格数据进行数值转换，并只保留非空、非零的价格
            price_source['最新价'] = pd.to_numeric(price_source['最新价'], errors='coerce')
            price_source = price_source[
                (price_source['最新价'].notna()) &
                (price_source['最新价'] > 0)
                ].copy()

            # 3. 关键修改点：根据用户要求，按 "股票简称" 进行去重（处理非唯一性问题）
            price_source = price_source.drop_duplicates(subset=[price_source_key], keep='first')

        # 4. 移除旧的 '最新价' 列 (来自XSTP或之前的合并)
        final_df.drop(columns=['最新价'], errors='ignore', inplace=True)

        # 5. 合并价格 (使用 '股票简称' 或回退键)
        if price_source_key in final_df.columns:
            # 确保合并键是字符串类型
            final_df[price_source_key] = final_df[price_source_key].astype(str)
            price_source[price_source_key] = price_source[price_source_key].astype(str)

            final_df = pd.merge(final_df, price_source, on=price_source_key, how='left')

        # 打印诊断信息
        valid_prices_count = final_df['最新价'].notna().sum() if '最新价' in final_df.columns else 0
        print(
            f"  - 实时行情数据 (最新价) 成功通过 '{price_source_key}' 关联的有效价格数量: {valid_prices_count} / {len(final_df)}")

        # 6. 填充空值
        final_df['股票简称'] = final_df['股票简称'].fillna('N/A')
        # 将价格的 NaN 填充为 'N/A'
        final_df['最新价'] = final_df['最新价'].fillna('N/A')
        # --- V5 价格获取和清洗增强结束 ---

        # 3. 合并信号和细节 (以下合并仍然使用股票代码，因为它更可靠)
        # A. 主力研报信号 (使用买入次数)
        report_df = processed_data['processed_main_report'][['股票代码', '机构投资评级(近六个月)-买入']]
        report_df.rename(columns={'机构投资评级(近六个月)-买入': '研报买入次数'}, inplace=True)
        final_df = pd.merge(final_df, report_df, on='股票代码', how='left')
        final_df['研报买入次数'] = pd.to_numeric(final_df['研报买入次数'], errors='coerce').fillna(0).astype(int)

        # B. 均线信号 (多头排列)
        xstp_df = processed_data['processed_xstp_df']
        xstp_cols = ['股票代码', '完全多头排列', '当前价格', '10日均线最新价', '30日均线最新价', '60日均线最新价']

        # V8 修复: 严格检查数据框是否包含数据和关键合并列，否则跳过合并。
        if not xstp_df.empty and '股票代码' in xstp_df.columns:
            # 1. 筛选出实际存在的列
            cols_present = [col for col in xstp_cols if col in xstp_df.columns]

            # 2. 执行去重和合并
            # 此时 xstp_df 肯定包含 '股票代码'，所以 drop_duplicates 是安全的
            merge_df = xstp_df[cols_present].drop_duplicates(subset=['股票代码'])

            # 3. 执行合并
            final_df = pd.merge(final_df, merge_df, on='股票代码', how='left')

        # V9 修复：确保 '完全多头排列' 列始终存在，无论 merge 是否跳过。
        if '完全多头排列' not in final_df.columns:
            final_df['完全多头排列'] = '否'
        else:
            # 如果存在，则将合并产生的 NaN 填充为 '否'
            final_df['完全多头排列'] = final_df['完全多头排列'].fillna('否')

        # C. 资金流向 (标记前100)
        # 确保数据源非空
        if not processed_data['market_fund_flow_raw'].empty:
            fund_flow_codes = processed_data['market_fund_flow_raw']['股票代码'].tolist()
            final_df['资金流入前100'] = final_df['股票代码'].apply(lambda x: '是' if x in fund_flow_codes else '否')
        else:
            final_df['资金流入前100'] = '否'

        # D. 强势股池
        if not processed_data['strong_stocks_raw'].empty:
            strong_codes = processed_data['strong_stocks_raw']['股票代码'].tolist()
            final_df['强势股'] = final_df['股票代码'].apply(lambda x: '是' if x in strong_codes else '否')
        else:
            final_df['强势股'] = '否'

        # E. 连续上涨天数
        rise_df = processed_data['consecutive_rise_raw']
        if not rise_df.empty:
            rise_df = rise_df[['股票代码', '连涨天数']].drop_duplicates(subset=['股票代码'])
            final_df = pd.merge(final_df, rise_df, on='股票代码', how='left').fillna({'连涨天数': 0})
        else:
            final_df['连涨天数'] = 0

        final_df['连涨天数'] = final_df['连涨天数'].astype(int)

        # F. 量价齐升
        if not processed_data['ljqs_raw'].empty:
            ljqs_codes = processed_data['ljqs_raw']['股票代码'].tolist()
            final_df['量价齐升'] = final_df['股票代码'].apply(lambda x: '是' if x in ljqs_codes else '否')
        else:
            final_df['量价齐升'] = '否'

        # G. 持续放量天数
        cxfl_df = processed_data['cxfl_raw']
        if not cxfl_df.empty:
            cxfl_df = cxfl_df[['股票代码', '放量天数']].drop_duplicates(subset=['股票代码'])
            final_df = pd.merge(final_df, cxfl_df, on='股票代码', how='left').fillna({'放量天数': 0})
        else:
            final_df['放量天数'] = 0

        final_df['放量天数'] = final_df['放量天数'].astype(int)

        # H. TA 信号细节：现在将 TA 信号作为独立列合并 (新逻辑)

        ta_dfs_to_merge = []

        # 1. MACD
        macd_df = processed_data.get('MACD', pd.DataFrame())
        if not macd_df.empty:
            ta_dfs_to_merge.append(macd_df[['股票代码', 'MACD_Signal']].rename(
                columns={'MACD_Signal': 'MACD_Signal'}))

        # 2. KDJ
        kdj_df = processed_data.get('KDJ', pd.DataFrame())
        if not kdj_df.empty:
            ta_dfs_to_merge.append(kdj_df[['股票代码', 'KDJ_Signal']].rename(
                columns={'KDJ_Signal': 'KDJ_Signal'}))

        # 3. CCI
        cci_df = processed_data.get('CCI', pd.DataFrame())
        if not cci_df.empty:
            # 只保留信号的文字描述，移除数值
            cci_df['CCI_Signal'] = cci_df['CCI_Signal'].astype(str).str.split(' ').str[0]
            ta_dfs_to_merge.append(cci_df[['股票代码', 'CCI_Signal']].rename(
                columns={'CCI_Signal': 'CCI_Signal'}))

        # 4. RSI
        rsi_df = processed_data.get('RSI', pd.DataFrame())
        if not rsi_df.empty:
            # 只保留信号的文字描述，移除数值
            rsi_df['RSI_Signal'] = rsi_df['RSI_Signal'].astype(str).str.split(' ').str[0]
            ta_dfs_to_merge.append(rsi_df[['股票代码', 'RSI_Signal']].rename(
                columns={'RSI_Signal': 'RSI_Signal'}))

        # 5. BOLL
        boll_df = processed_data.get('BOLL', pd.DataFrame())
        if not boll_df.empty:
            ta_dfs_to_merge.append(boll_df[['股票代码', 'BOLL_Signal']].rename(
                columns={'BOLL_Signal': 'BOLL_Signal'}))

        # 将所有 TA 信号合并到 final_df
        for ta_df in ta_dfs_to_merge:
            final_df = pd.merge(final_df, ta_df.drop_duplicates(subset=['股票代码']), on='股票代码', how='left')

        # 对新的 TA 信号列填充空值
        for col in ['MACD_Signal', 'KDJ_Signal', 'CCI_Signal', 'RSI_Signal', 'BOLL_Signal']:
            if col in final_df.columns:
                final_df[col] = final_df[col].fillna('')
            else:
                # 如果某个信号源为空，则补充空列以保持一致性
                final_df[col] = ''

        # 4. 过滤掉没有任何主要信号的股票
        def has_any_signal(row):
            # 这里的研报买入次数列在 run() 方法中已过滤，且在 merge 填充 NaN 为 0，故此处检查 > 0 即可
            return (row['研报买入次数'] > 0 or
                    row['完全多头排列'] == '是' or
                    row['强势股'] == '是' or
                    row['量价齐升'] == '是' or
                    row['MACD_Signal'] != '' or
                    row['KDJ_Signal'] != '' or
                    row['CCI_Signal'] != '' or
                    row['RSI_Signal'] != '' or
                    row['BOLL_Signal'] != ''
                    )

        final_df = final_df[final_df.apply(has_any_signal, axis=1)].copy()

        # 5. 整理输出并排序 (按研报买入次数、连涨天数、放量天数降序排序)
        final_df.sort_values(by=['研报买入次数', '连涨天数', '放量天数'], ascending=[False, False, False], inplace=True)
        final_df.reset_index(drop=True, inplace=True)
        final_df.insert(0, '序号', range(1, len(final_df) + 1))

        # --- V10 新增：添加股票代码搜索链接 ---
        BASE_URL = "https://www.baidu.com/s?wd="

        # 1. 使用现成的 format_stock_code 函数将6位代码转换为完整代码 (sh/sz前缀)
        final_df['完整股票代码'] = final_df['股票代码'].apply(format_stock_code)

        # 2. 拼接完整的搜索链接，列名改为 '股票链接'
        final_df['股票链接'] = BASE_URL + final_df['完整股票代码']

        # 3. 移除临时列
        final_df.drop(columns=['完整股票代码'], inplace=True, errors='ignore')
        # --- V10 新增结束 ---

        # 移除可能重复的 Current Price/Latest Price columns if they came from XSTP merge.
        if '当前价格' in final_df.columns and '最新价' in final_df.columns:
            final_df.drop(columns=['当前价格'], inplace=True, errors='ignore')

        # 最终列顺序 (手动调整，确保最重要的信息在前)
        base_cols = ['序号', '股票代码', '股票简称', '最新价']
        signal_cols = [
            '强势股', '量价齐升', '连涨天数', '放量天数',
            'MACD_Signal', 'KDJ_Signal', 'CCI_Signal', 'RSI_Signal', 'BOLL_Signal',
        ]
        report_cols = [
            '研报买入次数', '完全多头排列', '10日均线最新价', '30日均线最新价', '60日均线最新价',
            '资金流入前100',
        ]

        # 将新列 '股票链接' 添加到列列表的末尾
        final_cols = base_cols + signal_cols + report_cols + ['股票链接']
        final_df = final_df[[col for col in final_cols if col in final_df.columns]]

        return final_df

    def _generate_report(self, sheets_data: Dict[str, pd.DataFrame]):
        """生成 Excel 报告。"""
        print(f"\n>>> 正在生成 Excel 报告...")
        report_path = os.path.join(self.config.SAVE_DIRECTORY, f"股票筛选报告_{self.today_str}.xlsx")

        try:
            writer = pd.ExcelWriter(report_path, engine='xlsxwriter')
            workbook = writer.book

            # 定义格式
            header_format = workbook.add_format(
                {'bold': True, 'text_wrap': True, 'valign': 'top', 'fg_color': '#D7E4BC', 'border': 1})
            currency_format = workbook.add_format({'num_format': '#,##0.00'})
            code_format = workbook.add_format({'num_format': '@'})  # 文本格式

            for sheet_name, df in sheets_data.items():
                if df is None or df.empty:
                    print(f"  - 警告：工作表 '{sheet_name}' 数据为空，跳过创建。")
                    continue

                df.to_excel(writer, sheet_name=sheet_name, startrow=1, header=False, index=False)
                worksheet = writer.sheets[sheet_name]

                # 写入表头
                for col_num, value in enumerate(df.columns.values):
                    worksheet.write(0, col_num, value, header_format)

                # 设置列宽和格式
                for i, col in enumerate(df.columns):
                    max_len = max(df[col].astype(str).str.len().max(), len(col))
                    col_width = min(max_len + 2, 30)

                    # 修复：确保 '最新价' 列被正确识别为货币格式
                    if col == '最新价' or '价格' in col or '价' in col or '线' in col or '均线' in col:
                        worksheet.set_column(i, i, col_width, currency_format)
                    elif '代码' in col:
                        worksheet.set_column(i, i, 10, code_format)
                    else:
                        worksheet.set_column(i, i, col_width)

            writer.close()
            print(f"  - 报告已成功生成并保存到: {report_path}")

        except Exception as e:
            print(f"[FATAL] 致命错误：生成 Excel 报告失败。原因: {e}")
            raise

    def run(self):
        """主运行方法。"""
        print(f"股票分析程序启动 (Today: {self.today_str})")

        # 清理旧的临时文件 (只清理当日文件以外的)
        for filename in os.listdir(self.temp_dir):
            if not filename.endswith(f"{self.today_str}.txt"):
                try:
                    os.remove(os.path.join(self.temp_dir, filename))
                except Exception:
                    pass
        print("旧的临时数据文件清理完成。")

        try:
            # 1. 获取所有原始数据
            raw_data = self._get_all_raw_data()

            # 预处理主力研报数据
            processed_main_report = raw_data.get('main_report_raw', pd.DataFrame())
            spot_df = raw_data.get('spot_data_all', pd.DataFrame())

            # --- 对主力研报数据进行条件过滤 (买入评级 >= 1) ---
            report_col = '机构投资评级(近六个月)-买入'
            if not processed_main_report.empty and report_col in processed_main_report.columns:
                # 确保过滤列是数字类型
                processed_main_report[report_col] = pd.to_numeric(processed_main_report[report_col],
                                                                  errors='coerce').fillna(0)

                # 过滤条件：买入评级 >= 1
                processed_main_report = processed_main_report[processed_main_report[report_col] >= 1].copy()

                if processed_main_report.empty:
                    print("[WARN] 主力研报数据过滤后为空，回退至使用【A股实时行情】中的股票作为分析基础。")
                else:
                    print(">>> 主力研报数据已过滤，仅保留 '买入' 评级 >= 1 的股票。")

            # --- 核心筛选逻辑：基于过滤后的主力研报股票列表 ---
            if not processed_main_report.empty and '股票代码' in processed_main_report.columns:
                # 使用过滤后的列表作为分析基础
                all_codes = set(processed_main_report['股票代码'].unique())
            elif not spot_df.empty and '股票代码' in spot_df.columns:
                print("[WARN] 主力研报数据为空或无效，回退至使用【A股实时行情】中的股票作为分析基础。")
                # 使用实时行情中有效的股票代码进行分析
                all_codes = set(spot_df['股票代码'].unique())
            else:
                print("[FATAL] 无法获取有效的股票代码列表，流程终止。")
                return

            filtered_codes_list = list(all_codes)
            # --- 核心筛选逻辑结束 ---

            if not filtered_codes_list:
                print("未找到任何有效的股票代码，流程终止。")
                return

            # 2. 历史数据获取和技术指标计算
            hist_df_all = self._fetch_hist_data_parallel(filtered_codes_list, days=90)

            # 3. 技术指标信号提取
            ta_signals = self._process_ta_signals(filtered_codes_list, hist_df_all, spot_df)
            print(">>> 股票历史数据和技术指标分析完成。")

            # --- V6 修复：定义统一的股票筛选集，确保最终报告只包含分析的股票 ---
            universe_codes_set = set(filtered_codes_list)

            def filter_df_by_universe(df, universe_set):
                """将数据框限制在核心分析股票集合内。"""
                if df is None or df.empty or '股票代码' not in df.columns:
                    return pd.DataFrame()
                # 确保代码类型一致，以便于集合操作
                df['股票代码'] = df['股票代码'].astype(str)
                return df[df['股票代码'].isin(universe_set)].copy()

            # 4. 特殊数据处理和筛选 (必须对可能引入新代码的数据进行过滤)

            # A. 均线突破数据处理 (先处理，再对结果进行过滤)
            processed_xstp_df = self._process_xstp_and_filter(raw_data, spot_df)
            processed_xstp_df = filter_df_by_universe(processed_xstp_df, universe_codes_set)

            # B. 过滤其他每日排名数据 (直接过滤原始数据，因为它们在 _consolidate_data 中被用作 signal source)
            raw_data['market_fund_flow_raw'] = filter_df_by_universe(raw_data['market_fund_flow_raw'],
                                                                     universe_codes_set)
            raw_data['strong_stocks_raw'] = filter_df_by_universe(raw_data['strong_stocks_raw'], universe_codes_set)
            raw_data['consecutive_rise_raw'] = filter_df_by_universe(raw_data['consecutive_rise_raw'],
                                                                     universe_codes_set)
            raw_data['ljqs_raw'] = filter_df_by_universe(raw_data['ljqs_raw'], universe_codes_set)
            raw_data['cxfl_raw'] = filter_df_by_universe(raw_data['cxfl_raw'], universe_codes_set)

            # C. 行业板块成分股 (此表只用于报告输出，但过滤可确保一致性)
            raw_data['top_industry_cons_df'] = filter_df_by_universe(raw_data['top_industry_cons_df'],
                                                                     universe_codes_set)

            print(f">>> 已将所有信号数据源限制在 {len(universe_codes_set)} 个核心股票代码内。")
            # --- V6 修复结束 ---

            # 5. 合并所有数据源和信号
            processed_data = {
                **raw_data,
                **ta_signals,  # 技术指标信号
                'processed_xstp_df': processed_xstp_df,
                'processed_main_report': processed_main_report  # 使用过滤后的结果
            }
            # 替换评分环节，改为数据整合
            consolidated_report = self._consolidate_data(processed_data)

            # 6. 准备报告数据
            sheets_data = {
                '数据汇总': consolidated_report,  # 替换为数据汇总表
                '主力研报筛选': processed_data['processed_main_report'],
                '均线多头排列': processed_xstp_df,  # 使用处理后且过滤后的数据
                '实时行情': spot_df,  # 使用清洗后的数据
                '市场资金流向': raw_data['market_fund_flow_raw'],
                '强势股池': raw_data['strong_stocks_raw'],
                '连续上涨': raw_data['consecutive_rise_raw'],
                '量价齐升': raw_data['ljqs_raw'],
                '持续放量': raw_data['cxfl_raw'],
                'MACD金叉': ta_signals.get('MACD', pd.DataFrame()),
                'KDJ超卖金叉': ta_signals.get('KDJ', pd.DataFrame()),
                'CCI超卖': ta_signals.get('CCI', pd.DataFrame()),
                'RSI超卖': ta_signals.get('RSI', pd.DataFrame()),
                'BOLL低波': ta_signals.get('BOLL', pd.DataFrame()),
                '前十板块成分股': raw_data['top_industry_cons_df'],
            }

            # 7. 生成报告
            self._generate_report(sheets_data)

        except Exception as e:
            print(f"\n[FATAL] 致命错误：数据分析流程意外终止。原因: {e}")
            raise

        finally:
            end_time = time.time()
            print(f"\n>>> 流程结束。总耗时: {timedelta(seconds=end_time - self.start_time)}")


if __name__ == "__main__":
    # 这是程序的入口点，确保在文件作为脚本运行时，StockAnalyzer被创建并执行
    analyzer = StockAnalyzer()
    analyzer.run()
